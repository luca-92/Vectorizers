{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer\n",
    "In a large text corpus, some words will be very present (e.g. “the”, “a”, “is” in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.\n",
    "In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf–idf transform.\n",
    "Tf means term-frequency while tf–idf means term-frequency times inverse document-frequency:\n",
    "<img src=\"images/tfidf-general-formula.png\" style=\"width:331px;height:39px;\">\n",
    "where <i>idf(t)</i>:\n",
    "<img src=\"images/idf-default.png\" style=\"width:247px;height:65px;\">\n",
    "when <i>smooth_idf=True</i>.\n",
    "If <i>False</i> \n",
    "<img src=\"images/idf-False.png\" style=\"width:247px;height:65px;\"> \n",
    "At the end, everything is normalized by the Euclidian norm:\n",
    "<img src=\"images/euclidian-norm.png\" style=\"width:376px;height:66px;\">\n",
    "## First Example\n",
    "Let see the <b>fit</b> function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'and': 0, u'on': 3, u'the': 4, u'is': 2, u'cat': 1}\n[1.69314718 1.28768207 1.69314718 1.69314718 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = [\"The cat is on the and the cat\",\n",
    "        \"the\",\n",
    "        \"the cat\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(text)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second vector represent the idf of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34394851, 0.52316341, 0.34394851, 0.34394851, 0.60942458],\n       [0.        , 0.        , 0.        , 0.        , 1.        ],\n       [0.        , 0.78980693, 0.        , 0.        , 0.61335554]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = vectorizer.transform(text)\n",
    "vector.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every number represent its importance in according on its presence in the documents and the times that it appears in the document.\n",
    "Less is the number, and more the word will be considered if <i>tfidf</i> is set to <b>True</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
